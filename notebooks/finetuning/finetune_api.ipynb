{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning mistral 7B into MistralBluff\n",
    "\n",
    "The aime of this notebook is to finetune the pretrained model `mistral 7B v0.3` into a new model called `MistralBluff`. The new model will be trained on the `data/3_data_prepared_for_fine_tuning` dataset. The dataset comes from raw hands data of poker. The llm will be trained to emulate what the player 'IlxxxlI' would do in a given situation. The data is already preprocessed. This notebook sends the data to the mistral api and start the fine tuning process. The fine tuning process is done in the mistral api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path('./../../').resolve()\n",
    "\n",
    "CLEANED_DATA_DIR = ROOT_DIR / 'data/2_cleaned_data'\n",
    "PREPARED_DATA_DIR = ROOT_DIR / 'data/3_prepared_data'\n",
    "\n",
    "OUTPUT_FILE_NAME_TRAIN = 'anatole_data_train.json'\n",
    "OUTPUT_FILE_NAME_TEST = 'anatole_data_test.json'\n",
    "\n",
    "OUTPUT_FILE_MISTRAL_NAME_TRAIN = 'data_train.jsonl'\n",
    "OUTPUT_FILE_MISTRAL_NAME_TEST = 'data_test.jsonl'\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv('MISTRAL_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Final formating to fit mistral api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(CLEANED_DATA_DIR / OUTPUT_FILE_NAME_TRAIN)\n",
    "df_train=df.sample(frac=0.95,random_state=0)\n",
    "df_eval=df.drop(df_train.index)\n",
    "\n",
    "df_formatted = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": row[\"instruction\"]},\n",
    "            {\"role\": \"assistant\", \"content\": row[\"output\"]},\n",
    "        ]\n",
    "    }\n",
    "    for index, row in df_train.iterrows()\n",
    "]\n",
    "\n",
    "df_formatted2 = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": row[\"instruction\"]},\n",
    "            {\"role\": \"assistant\", \"content\": row[\"output\"]},\n",
    "        ]\n",
    "    }\n",
    "    for index, row in df_eval.iterrows()\n",
    "]\n",
    "\n",
    "with open(PREPARED_DATA_DIR / OUTPUT_FILE_MISTRAL_NAME_TRAIN, \"w\") as f:\n",
    "    for line in df_formatted:\n",
    "        json.dump(line, f)\n",
    "        f.write(\"\\n\")\n",
    "with open(PREPARED_DATA_DIR / OUTPUT_FILE_MISTRAL_NAME_TEST, \"w\") as f:\n",
    "    for line in df_formatted2:\n",
    "        json.dump(line, f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31077"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sending the data to the mistral api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "client = MistralClient(api_key=MISTRAL_API_KEY)\n",
    "\n",
    "with open(PREPARED_DATA_DIR / OUTPUT_FILE_MISTRAL_NAME_TRAIN, \"rb\") as f:\n",
    "    data_train = client.files.create(file=(OUTPUT_FILE_MISTRAL_NAME_TRAIN, f))\n",
    "with open(PREPARED_DATA_DIR / OUTPUT_FILE_MISTRAL_NAME_TEST, \"rb\") as f:\n",
    "    data_eval = client.files.create(file=(OUTPUT_FILE_MISTRAL_NAME_TEST, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Starting the fine tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai.models.jobs import TrainingParameters\n",
    "\n",
    "created_jobs = client.jobs.create(\n",
    "    model=\"open-mistral-7b\",\n",
    "    training_files=[data_train.id],\n",
    "    validation_files=[data_eval.id],\n",
    "    hyperparameters=TrainingParameters(\n",
    "        training_steps=10,\n",
    "        learning_rate=0.0001,\n",
    "        )\n",
    ")\n",
    "created_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object='job.metadata' training_steps=50 train_tokens_per_step=131072 data_tokens=4455124 train_tokens=6553600 epochs=1.471 expected_duration_seconds=300\n"
     ]
    }
   ],
   "source": [
    "from mistralai.models.jobs import TrainingParameters\n",
    "import asyncio\n",
    "\n",
    "dry_run_job = client.jobs.create(\n",
    "    model=\"open-mistral-7b\",\n",
    "    training_files=[data_train.id],\n",
    "    validation_files=[data_eval.id],\n",
    "    hyperparameters=TrainingParameters(\n",
    "        training_steps=150,\n",
    "        learning_rate=0.0001,\n",
    "    ),\n",
    "    dry_run=True,\n",
    ")\n",
    "print(dry_run_job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
